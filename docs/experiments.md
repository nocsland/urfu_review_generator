### Эксперименты

| **Эксперимент** | **Модель** | **Описание**                                                                                                                                                                                                                                                                                       | **Perplexity** | **Комментарии**                                                                                                                                   |
|-----------------|------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|---------------------------------------------------------------------------------------------------------------------------------------------------|
| 1               | Модель 3   | Самая простая модель, минимальная предобработка данных: нормализация скриптом, отсутствие лемматизации, не удалялись стоп-слова, не применялась балансировка классов. Модель обучалась 10 эпох. Выдала осмысленные, но шумные результаты.                                                          | 7.56           | Необходимы улучшения в алгоритме очистки данных и увеличение длительности обучения.                                                               |
| 2               | Модель 4   | Нормализация, лемматизация, удаление стоп-слов, балансировка методом случайного выбора отзывов с целевым рейтингом и перемешиванием. Шум минимален, но текст иногда терял связность. Обучение на 10 эпохах.                                                                                        | 7.56           | Возможно, проблема связности текста вызвана недостаточной проработкой этапа генерации.                                                            |
| 3               | Модель 5   | Те же этапы предобработки, что и в эксперименте 4, но для балансировки применялась замена слов на синонимы. Шум отсутствует, но проблема связности текста сохраняется. Обучение проводилось 5 эпох.                                                                                                | 8.35           | Увеличение количества эпох до 10-15, вероятно, улучшит результаты.                                                                                |
| 4               | Модель 6   | Новый алгоритм очистки данных: нормализация скриптом, но без лемматизации и удаления стоп-слов. Балансировка на основе нормализованных весовых коэффициентов, рассчитанных по группам отзывов. Обучение длилось 15 эпох. Результаты связные и чистые, но все же встречается небольшая несвязность. | 7.0            | В целом, более длительное обучение явно пошло на пользу, что подкрепляется метрикой, но необходимо продумать что может улучшить связность текста. |

### Выводы

Каждый эксперимент привел к улучшениям в качестве обработки данных и генерируемых текстов. Перспективными направлениями
для дальнейших экспериментов являются:

- Увеличение количества эпох для модели 5.
- Доработка алгоритма для улучшения связности текста в модели 6.

### P.S.

Следует рассмотреть нестандартный подход: обучить модель на не лемматизированных данных без удаления стоп-слов, а затем
дообучить ее на тех же данных, прошедших лемматизацию, нормализацию и удаление стоп-слов.
